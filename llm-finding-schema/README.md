# LLM Finding Schema Module

This module defines data models specifically for findings generated by Large Language Models (LLMs), including provenance tracking and telemetry.

## Purpose

The LLM Finding Schema module is responsible for:
- Defining `LLMInlineFinding` data structure
- Providing `LLMProvenance` for tracking LLM interactions
- Supporting `LLMRequestTelemetry` for performance monitoring
- Enabling `LLMInlineFindingIdFactory` for unique ID generation

## Key Components

### Core Classes
- `LLMInlineFinding` - LLM-generated finding structure
- `LLMProvenance` - LLM interaction tracking
- `LLMRequestTelemetry` - Performance and usage metrics
- `LLMInlineFindingIdFactory` - ID generation for LLM findings
- `LLMPostingEnvelope` - Packaging for LLM findings

### Data Structures
- Structured representation of LLM-generated issues
- Comprehensive provenance tracking
- Telemetry for LLM performance monitoring
- JSON serialization support

## Dependencies

- Gson - For JSON serialization
- Spring Context - For dependency injection
- LangChain4j - For LLM integration

## Usage

```java
LLMInlineFinding finding = LLMInlineFinding.builder()
    .id("llm-finding-id")
    .message("LLM-generated feedback")
    .confidence(0.85)
    .provenance(provenance)
    .telemetry(telemetry)
    .build();
```

## LLM Integration

### Provenance Tracking
- Model information and version
- Prompt used for generation
- Token usage statistics
- Response timing

### Telemetry Collection
- Request/response times
- Token consumption
- Model performance metrics
- Error tracking

## Testing

The module includes comprehensive tests covering:
- Data structure validation
- JSON serialization/deserialization
- ID generation and uniqueness
- Telemetry collection
- Integration with LangChain4j
